{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louis George    \n",
    "\n",
    "## Feature Engineering of Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/df_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IMDb_score</th>\n",
       "      <th>RT_score</th>\n",
       "      <th>Gross_world</th>\n",
       "      <th>Budget</th>\n",
       "      <th>scripts</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.68</td>\n",
       "      <td>53478166</td>\n",
       "      <td>30000000</td>\n",
       "      <td>TEN THINGS I HA...</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.76</td>\n",
       "      <td>7537453</td>\n",
       "      <td>4000000</td>\n",
       "      <td>\\n  \\n\\n\\n\\n\\nCUT FROM BLACK\\n\\nTITLE: FIN\\n...</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73</td>\n",
       "      <td>119195</td>\n",
       "      <td>400000</td>\n",
       "      <td>\\n          \\n          \\n         ...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>168839459</td>\n",
       "      <td>29000001</td>\n",
       "      <td>TWELVE MONKEYS\\n     \\n            An orig...</td>\n",
       "      <td>Drama|SciFi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.95</td>\n",
       "      <td>187733202</td>\n",
       "      <td>20000000</td>\n",
       "      <td>12 YEARS A SLAVE\\...</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IMDb_score  RT_score  Gross_world    Budget  \\\n",
       "0        0.73      0.68     53478166  30000000   \n",
       "1        0.77      0.76      7537453   4000000   \n",
       "2        0.75      0.73       119195    400000   \n",
       "3        0.80      0.89    168839459  29000001   \n",
       "4        0.81      0.95    187733202  20000000   \n",
       "\n",
       "                                             scripts                genres  \n",
       "0                                 TEN THINGS I HA...        Comedy|Romance  \n",
       "1    \\n  \\n\\n\\n\\n\\nCUT FROM BLACK\\n\\nTITLE: FIN\\n...                Comedy  \n",
       "2             \\n          \\n          \\n         ...                 Drama  \n",
       "3      TWELVE MONKEYS\\n     \\n            An orig...  Drama|SciFi|Thriller  \n",
       "4                               12 YEARS A SLAVE\\...                 Drama  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummying the genres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df, df['genres'].str.get_dummies()), axis=1).drop('genres', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1210, 26)"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the Scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizer takes in a tokenizer. We then use this blown up df in models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "# Create a blank Tokenizer with just the English vocab\n",
    "tokenizer = Tokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nlp(df['scripts'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                False\n",
      "TEN True\n",
      "THINGS False\n",
      "I True\n",
      "HATE False\n",
      "ABOUT True\n",
      "YOU True\n",
      "\n",
      "          \n",
      "                 False\n",
      "written False\n",
      "by True\n",
      "Karen False\n",
      "McCullah False\n",
      "Lutz False\n",
      "& False\n",
      "Kirsten False\n",
      "Smith False\n",
      "\n",
      "          \n",
      "               False\n",
      "based False\n",
      "on True\n",
      "' False\n",
      "Taming False\n",
      "of True\n",
      "the True\n",
      "Shrew False\n",
      "\" False\n",
      "by True\n",
      "William False\n",
      "Shakespeare False\n",
      "\n",
      "          \n",
      "           False\n",
      "Revision False\n",
      "November False\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in tokens:\n",
    "    print(i, i.is_stop)\n",
    "    count += 1\n",
    "    if count > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(string):\n",
    "    doc = nlp(string)\n",
    "    tokens = []\n",
    "    for token in doc:\n",
    "        if token.is_stop == False:\n",
    "            tokens.append(token.lemma_)\n",
    "        elif token.is_punct == False:\n",
    "            tokens.append(token.lemma_)\n",
    "        elif token.is_space == False:\n",
    "            tokens.append(token.lemma_)\n",
    "\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               \n",
      "TEN\n",
      "THINGS\n",
      "I\n",
      "HATE\n",
      "ABOUT\n",
      "YOU\n",
      "\n",
      "          \n",
      "                \n",
      "write\n",
      "by\n",
      "Karen\n",
      "McCullah\n",
      "Lutz\n",
      "&\n",
      "Kirsten\n",
      "Smith\n",
      "\n",
      "          \n",
      "              \n",
      "base\n",
      "on\n",
      "'\n",
      "Taming\n",
      "of\n",
      "the\n",
      "Shrew\n",
      "\"\n",
      "by\n",
      "William\n",
      "Shakespeare\n",
      "\n",
      "          \n",
      "          \n",
      "Revision\n",
      "November\n"
     ]
    }
   ],
   "source": [
    "temp = my_tokenizer(df['scripts'][0])\n",
    "count = 0\n",
    "\n",
    "for i in temp:\n",
    "    count += 1\n",
    "    print(i)\n",
    "    if count > 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df['scripts'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagowords = CountVectorizer(tokenizer=my_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = bagowords.fit_transform(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x3733 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4680 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\n                                                                                                                                                                                                                    651\n",
       "\\n\\n                                                                                                                                                                                                                  469\n",
       "\\n\\n\\n                                                                                                                                                                                                                 19\n",
       "\\n\\n\\n\\n                                                                                                                                                                                                                2\n",
       "\\n\\n\\n                                                                                                                                                                                                                  1\n",
       "\\n\\n\\n                                                                                                                                                                                                                162\n",
       "\\n\\n\\n                                                                                                                                                                                                                  2\n",
       "\\n\\n                                                                                                                                                                                                                    1\n",
       "\\n\\n \\n                                                                                                                                                                                                                 3\n",
       "\\n\\n  \\n                                                                                                                                                                                                                1\n",
       "\\n\\n  \\n                                                                                                                                                                                                                4\n",
       "\\n\\n                                                                                                                                                                                                                  315\n",
       "\\n\\n                                                                                                                                                                                                                    2\n",
       "\\n\\n                                                                                                                                                                                                                    1\n",
       "\\n\\n          \\n                                                                                                                                                                                                        1\n",
       "\\n\\n                                                                                                                                                                                                                    1\n",
       "\\n                                                                                                                                                                                                                    784\n",
       "\\n \\n                                                                                                                                                                                                                   8\n",
       "\\n \\n\\n                                                                                                                                                                                                                 2\n",
       "\\n \\n\\n                                                                                                                                                                                                                 1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df = pd.DataFrame(columns=bagowords.get_feature_names(), data=test.toarray())\n",
    "my_df.sum().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
