{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have optimized my two models, I need to train a new final, and complete model with the parameters which I found to be optimal, but on the full dataset.\n",
    "\n",
    "This means that I'll have to revectorize, save that fit vectorizer (to vectorize new inputs from the webapp), \n",
    "\n",
    "Can I just build a pipeline that includes this? I think I could just build and fit a pipeline with all the optimized settings, and then run predictions on inputs if I format them the same as those of the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louis George\n",
    "## Making the final models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../../data/X_plus.csv')\n",
    "y = pd.read_csv('../../data/y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_imdb = y.loc[:, 'IMDb_score']\n",
    "y_rt = y.loc[:, 'RT_score']\n",
    "y_profit = y.loc[:, 'Per_Profit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_preprocessor(string):\n",
    "    no_d = ''.join([i for i in string if not i.isdigit()])\n",
    "    return no_d.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(string):\n",
    "    # Initializing the spacy class\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(string)\n",
    "    # List to append accepted tokens to\n",
    "    tokens = []\n",
    "    # Condition for a good token\n",
    "    for token in doc:\n",
    "\n",
    "        if (token.is_stop == False) & \\\n",
    "           (token.is_punct == False) & \\\n",
    "           (token.is_space == False) & \\\n",
    "           ('\\n' not in str(token)):\n",
    "            \n",
    "            tokens.append(token.lemma_)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will take a long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the vectorizer\n",
    "tfidf = TfidfVectorizer(min_df=0.1, \n",
    "                        max_df=0.9, \n",
    "                        preprocessor=my_preprocessor, \n",
    "                        tokenizer=my_tokenizer, \n",
    "                        ngram_range=(1,3)).fit(X['scripts'])\n",
    "\n",
    "# Exporting the fit vectorizer\n",
    "joblib.dump(tfidf, '../models/full_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the transformed dataset with the other features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming all of the scripts (will take awhile)\n",
    "X_transformed = tfidf.transform(X['scripts'])\n",
    "# Turning it into a dataframe\n",
    "X_vecs = pd.DataFrame(columns=tfidf.get_feature_names(), data=X_transformed.toarray())\n",
    "# Merging all of the features\n",
    "X_merged = pd.concat([X.drop('scripts', axis=1).reset_index(drop=True), X_vecs], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting all of the optimized models for hyper parameter selection\n",
    "print(joblib.load('../models/IMDb_logreg.pkl'))\n",
    "print(joblib.load('../models/Rotten_logreg.pkl'))\n",
    "print(joblib.load('../models/Profit_logreg.pkl'))\n",
    "print(joblib.load('../models/IMDb_xgbc.pkl'))\n",
    "print(joblib.load('../models/Rotten_xgbc.pkl'))\n",
    "print(joblib.load('../models/Profit_xgbc.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDb Score Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=0.1, \n",
    "                            penalty='l2').fit(X_merged, y_imdb)\n",
    "joblib.dump(logreg, '../models/imdb_logreg_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coefs = pd.DataFrame({'Coef':X_merged.columns,\n",
    "                         'Value':logreg.coef_[0]})\n",
    "lr_t10 = lr_coefs.sort_values(by='Value', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.barh(lr_t10['Coef'], abs(lr_t10['Value']))\n",
    "plt.title(\"Features with the Highest Coefficient \\n Logistic Regression\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.savefig(f\"../plots/imdb_logreg_full.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(max_depth=7, \n",
    "                     learning_rate=0.01, \n",
    "                     n_estimator=200).fit(X_train_tfidf, y_imdb_train)\n",
    "joblib.dump(logreg, '../models/imdb_xgbc_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_coefs = pd.DataFrame({'Coef':X_train_tfidf.columns,\n",
    "                         'Value':xgbc.feature_importances_})\n",
    "xg_t10 = xg_coefs.sort_values(by='Value', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.barh(xg_t10['Coef'], abs(xg_t10['Value']))\n",
    "plt.title(\"Features with the Highest Gain \\n XG Boost\")\n",
    "plt.xlabel(\"Gain\")\n",
    "plt.savefig(f\"../plots/imdb_xgbc_full.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RT Score Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=1.0, \n",
    "                            penalty='l1').fit(X_merged, y_rt)\n",
    "joblib.dump(logreg, '../models/rt_logreg_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coefs = pd.DataFrame({'Coef':X_merged.columns,\n",
    "                         'Value':logreg.coef_[0]})\n",
    "lr_t10 = lr_coefs.sort_values(by='Value', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.barh(lr_t10['Coef'], abs(lr_t10['Value']))\n",
    "plt.title(\"Features with the Highest Coefficient \\n Logistic Regression\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.savefig(f\"../plots/rt_logreg_full.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(learning_rate=0.1, \n",
    "                     max_depth=4, \n",
    "                     n_estimators=100).fit(X_merged, y_rt)\n",
    "joblib.dump(logreg, '../models/rt_xgbc_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_coefs = pd.DataFrame({'Coef':X_merged.columns,\n",
    "                         'Value':xgbc.feature_importances_})\n",
    "xg_t10 = xg_coefs.sort_values(by='Value', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.barh(xg_t10['Coef'], abs(xg_t10['Value']))\n",
    "plt.title(\"Features with the Highest Gain \\n XG Boost\")\n",
    "plt.xlabel(\"Gain\")\n",
    "plt.savefig(f\"../plots/rt_xgbc_full.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(C=0.1, \n",
    "                            penalty='l1').fit(X_merged, y_profit)\n",
    "joblib.dump(logreg, '../models/profit_logreg_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_coefs = pd.DataFrame({'Coef':X_merged.columns,\n",
    "                         'Value':logreg.coef_[0]})\n",
    "lr_t10 = lr_coefs.sort_values(by='Value', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.barh(lr_t10['Coef'], abs(lr_t10['Value']))\n",
    "plt.title(\"Features with the Highest Coefficient \\n Logistic Regression\")\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.savefig(f\"../plots/profit_logreg_full.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = XGBClassifier(learning_rate=0.1, \n",
    "                     max_depth=5, \n",
    "                     n_estimators=80).fit(X_merged, y_profit)\n",
    "joblib.dump(logreg, '../models/profit_xgbc_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_coefs = pd.DataFrame({'Coef':X_merged.columns,\n",
    "                         'Value':xgbc.feature_importances_})\n",
    "xg_t10 = xg_coefs.sort_values(by='Value', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.barh(xg_t10['Coef'], abs(xg_t10['Value']))\n",
    "plt.title(\"Features with the Highest Gain \\n XG Boost\")\n",
    "plt.xlabel(\"Gain\")\n",
    "plt.savefig(f\"../plots/profit_xgbc_full.png\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
